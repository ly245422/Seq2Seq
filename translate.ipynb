{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器翻译实验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 安装依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: jieba in d:\\anaconda\\lib\\site-packages (0.42.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 导入依赖库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import jieba\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 定义数据路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"data/cmn.txt\"        ## 数据集文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 定义预处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_eng(text):\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    # 单词和标点之间加空格\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    text = re.sub(r\"([?.!,])\", r\" \\1 \",text)\n",
    "    # 多个空格合并为一个\n",
    "    text = re.sub(r'[\" \"]+', \" \", text)\n",
    "\n",
    "    # 除了(a-z, A-Z, \".\", \"?\", \"!\", \",\")这些字符外，全替换成空格\n",
    "    text = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", text)\n",
    "    text = text.rstrip().strip()\n",
    "\n",
    "    # 增加开始结束标志，让模型知道何时停止预测\n",
    "    text = '<start> ' + text + ' <end>'\n",
    "    return text\n",
    "\n",
    "def preprocess_chn(text):\n",
    "    text = text.lower().strip()\n",
    "    text = jieba.cut(text, cut_all=False, HMM=True)\n",
    "    text = \" \".join(list(text))  # 词之间增加空格\n",
    "    text = '<start> ' + text + ' <end>'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n",
      "<start> 我 可以 借 这 本书 吗 ？ <end>\n"
     ]
    }
   ],
   "source": [
    "en_sentence = \"May I borrow this book?\"\n",
    "chn_sentence = \"我可以借这本书吗？\"\n",
    "print(preprocess_eng(en_sentence))\n",
    "print(preprocess_chn(chn_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 提取双语数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_texts, cn_texts = [], []\n",
    "for line in open(path_to_file, encoding='UTF-8').read().strip().split('\\n'):\n",
    "    en_text, cn_text = line.split('\\t')\n",
    "    en_text_prep, cn_text_prep = preprocess_eng(en_text), preprocess_chn(cn_text)\n",
    "    en_texts.append(en_text_prep)\n",
    "    cn_texts.append(cn_text_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> if a person has not had a chance to acquire his target language by the time he s an adult , he s unlikely to be able to reach native speaker level in that language . <end>\n",
      "<start> 如果 一個 人 在 成人 前 沒 有 機會習 得 目標 語言 ， 他 對 該 語言 的 認識 達 到 母語者 程度 的 機會 是 相當 小 的 。 <end>\n",
      "20403 20403\n"
     ]
    }
   ],
   "source": [
    "print(en_texts[-1])\n",
    "print(cn_texts[-1])\n",
    "print(len(en_texts), len(cn_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 文字ID映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_converter = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "en_converter.fit_on_texts(en_texts)\n",
    "cn_converter = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "cn_converter.fit_on_texts(cn_texts)\n",
    "\n",
    "en_text_ids = en_converter.texts_to_sequences(en_texts)\n",
    "cn_text_ids = cn_converter.texts_to_sequences(cn_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> hi . <end>\n",
      "[1, 1727, 3, 2]\n",
      "<start> 嗨 。 <end>\n",
      "[1, 2036, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "print(en_texts[0])\n",
    "print(en_text_ids[0])\n",
    "\n",
    "print(cn_texts[0])\n",
    "print(cn_text_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Padding填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "英文最大长度：38\n",
      "中文最大长度：32\n",
      "<start> hi . <end>\n",
      "[   1 1727    3    2    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "<start> 嗨 。 <end>\n",
      "[   1 2036    3    2    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "max_en_len = max([len(seq) for seq in en_text_ids])\n",
    "max_cn_len = max([len(seq) for seq in cn_text_ids])\n",
    "print(\"英文最大长度：{}\".format(max_en_len))\n",
    "print(\"中文最大长度：{}\".format(max_cn_len))\n",
    "\n",
    "en_text_ids_padded = tf.keras.preprocessing.sequence.pad_sequences(en_text_ids, maxlen=max_en_len, padding='post')\n",
    "cn_text_ids_padded = tf.keras.preprocessing.sequence.pad_sequences(cn_text_ids, maxlen=max_cn_len, padding='post')\n",
    "\n",
    "print(en_texts[0])\n",
    "print(en_text_ids_padded[0])\n",
    "\n",
    "print(cn_texts[0])\n",
    "print(cn_text_ids_padded[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 分割训练、验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19382 19382 1021 1021\n"
     ]
    }
   ],
   "source": [
    "# 中文为源语言，英文为目标语言\n",
    "# 分割训练数据和验证数据\n",
    "input_cn_train, input_cn_val, target_en_train, target_en_val = train_test_split(\n",
    "    cn_text_ids_padded, en_text_ids_padded, test_size=0.05)\n",
    "\n",
    "# 显示训练数据和验证数据的大小\n",
    "print(len(input_cn_train), len(target_en_train),\n",
    "      len(input_cn_val), len(target_en_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 转换成tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先做shuffle， 再取batch\n",
    "batch_size=64\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((input_cn_train, target_en_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "train_dataset = train_dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((input_cn_val, target_en_val))\n",
    "valid_dataset = valid_dataset.batch(batch_size=batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 32), dtype=int32, numpy=\n",
       " array([[   1, 6119,  147, ...,    0,    0,    0],\n",
       "        [   1,   63,    7, ...,    0,    0,    0],\n",
       "        [   1, 3172,  392, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [   1,   14, 1927, ...,    0,    0,    0],\n",
       "        [   1,   14,   15, ...,    0,    0,    0],\n",
       "        [   1,   12, 3261, ...,    0,    0,    0]])>,\n",
       " <tf.Tensor: shape=(64, 38), dtype=int32, numpy=\n",
       " array([[   1,    5,  480, ...,    0,    0,    0],\n",
       "        [   1,   77,    7, ...,    0,    0,    0],\n",
       "        [   1,    5, 2034, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [   1,   13,   51, ...,    0,    0,    0],\n",
       "        [   1,   13,  111, ...,    0,    0,    0],\n",
       "        [   1,   18, 1820, ...,    0,    0,    0]])>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(valid_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 配置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "hidden_units = 1024\n",
    "# 0 是为padding保留的一个特殊id， 所以要 + 1\n",
    "cn_vocab_size = len(cn_converter.word_index) + 1\n",
    "en_vocab_size = len(en_converter.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 定义Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        # vacab_size=vocab_inp_size=9394, embedding_dim=256 enc_units=1024 batch_sz=64\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       #recurrent_activation='sigmoid',\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        # x 是训练数据，shape == (batch_size，max_length)  -> (64, 46)\n",
    "        \n",
    "        # embedding 后得到每个词的词向量, x shape == (batch_size, max_length, embedding_dim) -> (64, 46, 256)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # 在GRU中，每一个时间步，输出层和隐藏层是相等的\n",
    "        # output 是所有时间步的输出层输出 shape == (batch_size, max_length, units) -> (64, 46, 1024)\n",
    "        # state 是最后一个时间步的隐藏层输出, shape == (batch_size, units) -> (64, 1024)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        # 初始化gru的隐层参数,  shape == (batch_size, units) -> (64,1024)\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 定义Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query shape == (batch_size, hidden size)\n",
    "        # 扩展时间维度 shape == (batch_size, 1, hidden size)\n",
    "        # 为了计算后面的 score\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # score 维度为1是因为应用了self.V, V的维度是1\n",
    "        # 应用self.V前后的维度是 (batch_size, max_length, units) --> (batch_size, max_length, 1)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # 使用softmax得到attention的权重， attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        # 相加后的attention 上下文向量的维度：shape context_vector == (batch_size, hidden_size)\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 定义Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        # vocab_size=vocab_tar_size=6082, embedding_dim=256, dec_units=1024, batch_sz=64\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        # 输出的维度是目标语言词汇表的大小，返回的是softmax概率，词汇表中每一个词的概率\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "\n",
    "        # 计算decoder的第一个隐状态和encoder所有输入之间的attention 权重， 得到上下文向量, context_vector\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # embedding后的维度 == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # 把上下文向量context_vector 和 输入embedding拼接在一起\n",
    "        # context_vector shape == (batch_size, units) -> (64, 1024)\n",
    "        # 拼接后的数据维度 == (batch_size, 1, embedding_dim + hidden_size) -> (64, 1, 1024 + 256)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # 把拼接后的向量输入gru\n",
    "        # 得到当前时间步的输出和隐状态\n",
    "        # output shape == (batch_size, 1, units) -> (64, 1, 1024), state shape == (batch_size, units) -> (64,1024)\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size, hidden_size=1024)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab) -> (64, 6082)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(cn_vocab_size, embedding_dim, hidden_units, batch_size)\n",
    "decoder = Decoder(en_vocab_size, embedding_dim, hidden_units, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 定义优化器和损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    \"\"\"Calculate the loss value\n",
    "\n",
    "    Args:\n",
    "        real: the true label  shape == (batch_size,) -> (64,)\n",
    "        pred: the probability of each word from the vocabulary, is the output from the decoder \n",
    "                 shape == (batch_size, vocab_size) -> (64, 6082)\n",
    "\n",
    "    Returns: \n",
    "        the average loss of the data in a batch size\n",
    "    \"\"\"\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 定义checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './checkpoint'\n",
    "checkpoint_prefix = checkpoint_dir +  '/seq2seq_mt_ckpt'\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)\n",
    "fine_tune = True\n",
    "pretrain_ckpt = \"pre_model/pretrain_ckpt\"\n",
    "if fine_tune:\n",
    "    checkpoint.restore(pretrain_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6 定义训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        # decoder的第一个输入为 '<start>'\n",
    "        # dec input shape == (batch_size, 1) -> (64, 1)\n",
    "        dec_input = tf.expand_dims(\n",
    "            [en_converter.word_index['<start>']] * batch_size, 1)\n",
    "        # 将当前输出作为下一步的输入\n",
    "        # 第一个输入为 <start>, 所有 t 从 1 开始 (不是 0)\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(\n",
    "                dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            # 计算当前timestep的损失\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # 更新输入为上一时刻的输出\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    # 聚合所有参数\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    # 计算梯度\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    # 根据梯度更新变量\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.7 启动训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_32616\\2729203214.py\", line 6, in train_step  *\n        enc_output, enc_hidden = encoder(inp, enc_hidden)\n    File \"d:\\anaconda\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_filel3kbo1_3.py\", line 11, in tf__call\n        (output, state) = ag__.converted_call(ag__.ld(self).gru, (ag__.ld(x),), dict(initial_state=ag__.ld(hidden)), fscope)\n\n    AttributeError: Exception encountered when calling layer 'encoder_1' (type Encoder).\n    \n    in user code:\n    \n        File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_32616\\4060373263.py\", line 23, in call  *\n            output, state = self.gru(x, initial_state=hidden)\n        File \"d:\\anaconda\\lib\\site-packages\\keras\\src\\layers\\rnn\\base_rnn.py\", line 626, in __call__  **\n            return super().__call__(inputs, **kwargs)\n        File \"d:\\anaconda\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n            raise e.with_traceback(filtered_tb) from None\n        File \"d:\\anaconda\\lib\\site-packages\\keras\\src\\layers\\rnn\\gru.py\", line 851, in _defun_gru_call\n            \"kernel\": gru_lstm_utils.read_variable_value(self.cell.kernel),\n    \n        AttributeError: Exception encountered when calling layer 'gru_2' (type GRU).\n        \n        'GRUCell' object has no attribute 'kernel'\n        \n        Call arguments received by layer 'gru_2' (type GRU):\n          • inputs=tf.Tensor(shape=(64, 32, 256), dtype=float32)\n          • mask=None\n          • training=None\n          • initial_state=['tf.Tensor(shape=(64, 1024), dtype=float32)']\n    \n    \n    Call arguments received by layer 'encoder_1' (type Encoder):\n      • x=tf.Tensor(shape=(64, 32), dtype=int32)\n      • hidden=tf.Tensor(shape=(64, 1024), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (batch, (inp, targ)) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_dataset)):\n\u001b[1;32m---> 11\u001b[0m     batch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_hidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32md:\\anaconda\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileyi_uffll.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[1;34m(inp, targ, enc_hidden)\u001b[0m\n\u001b[0;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m---> 12\u001b[0m     (enc_output, enc_hidden) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(encoder), (ag__\u001b[38;5;241m.\u001b[39mld(inp), ag__\u001b[38;5;241m.\u001b[39mld(enc_hidden)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     13\u001b[0m     dec_hidden \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(enc_hidden)\n\u001b[0;32m     14\u001b[0m     dec_input \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mexpand_dims, ([ag__\u001b[38;5;241m.\u001b[39mld(en_converter)\u001b[38;5;241m.\u001b[39mword_index[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<start>\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m*\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(batch_size), \u001b[38;5;241m1\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[1;32md:\\anaconda\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filel3kbo1_3.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m     10\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39membedding, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 11\u001b[0m (output, state) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mgru, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28mdict\u001b[39m(initial_state\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(hidden)), fscope)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_32616\\2729203214.py\", line 6, in train_step  *\n        enc_output, enc_hidden = encoder(inp, enc_hidden)\n    File \"d:\\anaconda\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\__autograph_generated_filel3kbo1_3.py\", line 11, in tf__call\n        (output, state) = ag__.converted_call(ag__.ld(self).gru, (ag__.ld(x),), dict(initial_state=ag__.ld(hidden)), fscope)\n\n    AttributeError: Exception encountered when calling layer 'encoder_1' (type Encoder).\n    \n    in user code:\n    \n        File \"C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_32616\\4060373263.py\", line 23, in call  *\n            output, state = self.gru(x, initial_state=hidden)\n        File \"d:\\anaconda\\lib\\site-packages\\keras\\src\\layers\\rnn\\base_rnn.py\", line 626, in __call__  **\n            return super().__call__(inputs, **kwargs)\n        File \"d:\\anaconda\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n            raise e.with_traceback(filtered_tb) from None\n        File \"d:\\anaconda\\lib\\site-packages\\keras\\src\\layers\\rnn\\gru.py\", line 851, in _defun_gru_call\n            \"kernel\": gru_lstm_utils.read_variable_value(self.cell.kernel),\n    \n        AttributeError: Exception encountered when calling layer 'gru_2' (type GRU).\n        \n        'GRUCell' object has no attribute 'kernel'\n        \n        Call arguments received by layer 'gru_2' (type GRU):\n          • inputs=tf.Tensor(shape=(64, 32, 256), dtype=float32)\n          • mask=None\n          • training=None\n          • initial_state=['tf.Tensor(shape=(64, 1024), dtype=float32)']\n    \n    \n    Call arguments received by layer 'encoder_1' (type Encoder):\n      • x=tf.Tensor(shape=(64, 32), dtype=int32)\n      • hidden=tf.Tensor(shape=(64, 1024), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3  # 50 测试需要，设置训练轮数为3， 实际为保证效果，建议设置为50\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    # 获取gru的初始状态\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(iter(train_dataset)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                         batch,\n",
    "                                                         batch_loss.numpy()))\n",
    "\n",
    "    # 每两个迭代保存一次模型\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 推理测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 定义推理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(sentence):\n",
    "    \"\"\"Translate a sentence\n",
    "\n",
    "    Args:\n",
    "        sentence: the test sentence        \n",
    "    \"\"\"\n",
    "\n",
    "    attention_plot = np.zeros((max_en_len, max_cn_len))\n",
    "\n",
    "    sentence = preprocess_chn(sentence)\n",
    "\n",
    "    # 词转ID\n",
    "    inputs = [cn_converter.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_cn_len, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    # hidden shape == (1, 1024)\n",
    "    hidden = [tf.zeros((1, hidden_units))]\n",
    "    # enc out shape == (1, max_length_inp, 1024) -> (1, 46, 1024)\n",
    "    # enc hidden shape == (1, 1024)\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([en_converter.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_en_len):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        # storing the attention weigths to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "#         print(attention_weights)\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        result += en_converter.index_word[predicted_id] + ' '\n",
    "\n",
    "        # 预测到 '<end>' 时停止\n",
    "        if en_converter.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # 当前输出作为下一次输入\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 定义attention可视化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    # cmap means color map, viridis means blue-green-yellow\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    # set the x-tick/y-tick labels with list of string labels\n",
    "    # ax.set_xticklabels([''] + sentence, fontdict=fontdict, fontproperties=font)\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict)\n",
    "    # ax.set_yticklabels([''] + predicted_sentence, fontproperties=font, fontdict=fontdict)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    # set tick locators\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 定义翻译测试函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = inference(sentence)\n",
    "\n",
    "    print('输入: %s' % (sentence))\n",
    "    print('翻译结果: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(\n",
    "        result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 离线加载预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint/seq2seq_mt_ckpt-26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fe5b6c575f8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = 'checkpoint'\n",
    "print(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "# 从最后一次checkpoint中恢复\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入: <start> 我 有 一只 猫 <end>\n",
      "翻译结果: i have a cat . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe5b6c57f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate('我有一只猫')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Seq2Seq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
